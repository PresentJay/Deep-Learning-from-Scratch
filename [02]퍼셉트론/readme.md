# 퍼셉트론(Perceptron)

- 1957년, 프랑크 로젠블라트의 알고리즘
- 신경망(딥러닝)의 기원
- 다수의 신호를 입력으로 받아, 하나의 신호를 출력

        [EX : 2입력 퍼셉트론]

        (x1) -w1-> (y)
        (x2) -w2-> (y)

- w는 weight(가중치)
- 괄호로 싸여진 객체 = 뉴런, 노드  
  <br>

> ## 01. 기본

          [퍼셉트론의 동작원리]
          y = 0 : (w1 X x1 + w2 X x2 <= Θ)
          y = 1 : (w1 X x1 + w2 X x2 > Θ)

- 노드에서 보낸 신호의 총합이 특정 임계값(세타기호로 표현, theta,Θ)을 넘길 때 1 (활성화)

<br>

> ## 02. 편향(bias)

- 위 [동작원리]에서 theta(Θ)를 -b로 치환하고 정리하면 아래와 같음

        [치환한 퍼셉트론의 동작원리]
        y = 0 : (b + w1 X x1 + w2 X x2 <= 0)
        y = 1 : (b + w1 X x1 + w2 X x2 > 0)

- 위 경우, b를 편향(bias)이라고 함

<br>

> ## 03. 다층 퍼셉트론(multi-layer perceptron)

- 퍼셉트론으로 XOR을 만들려고 하면, 이전과 같은 방식으로는 불가능하다 : 퍼셉트론의 한계(limit of perceptron)
- 왜냐하면 위 퍼셉트론의 입력에 대한 출력을 그래프상에 나타내고, NAND/OR/AND와 같은 동작을 입력에 대해 직선 하나를 그어 동작 영역(1인지 0인지)을 구별할 수 있었으나, XOR은 직선 하나로는 불가능하기 때문이다! (비선형/곡선이라면 되지만!)
- 그래서 위 경우, 퍼셉트론을 겹겹이 쌓아, "다층 퍼셉트론(multi-layer perceptron)"으로 해결할 수 있다!

<br><br><br>

> #### [C.f.01.] AND, NAND, OR 등 논리 게이트의 가중치(weight)의 매개변수 조합은 굉장히 많고, 코드에서 구현한 게이트의 가중치와 편향치 (0.5, 0.5 / -0.7) (-0.5, -0.5 / 0.7) 들은 그 중 하나의 예시일 뿐이다.
