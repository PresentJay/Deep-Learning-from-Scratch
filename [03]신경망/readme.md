# 신경망(Network)

- 가중치 매개변수의 적절한 값을 데이터로부터 자동으로 학습하는 능력이 바로 신경망의 성질!
- 신경망은 입력층, 은닉층, 출력층으로 나뉨!

<br>

        [은닉층]
        입력층, 출력층과 달리 사람에게 보이지 않음!

<br>
<br>

> ## 01. 활성화함수(activation function)

<br>

- 입력신호의 총합이 활성화를 일으키는지 정하는 역할!
- 입력신호의 총합을 출력신호로 변환하는 함수
- 활성화함수는 은닉층에서 h(a), 출력층에서 σ(a) - 시그마sigma 로 나타냄
- 그래서 기존의 퍼셉트론에서 가중치를 곱한 값과 편향을 모두 더하는 것을 a단계(계산단계)로 함.
- 이후 이 a를 활성화함수에 넣어 출력(y)를 보는 것이 흐름.
- 출력층의 활성화 함수는 풀고자 하는 문제에 따라 다르게 설정.
- 회귀 문제에서는 항등함수, two-class-classification에서는 시그모이드, multi-class-classification에서는 소프트맥스가 일반적

<br>

- 기존의 임계값 기준으로 출력이 바뀌는 함수를 "계단함수(step function)"라고 함.
- 그래서 퍼셉트론은 활성화함수로 "계단함수"를 이용한다고 말할 수 있음.

<br>

        계단함수 그래프

![](./image/01.PNG)

<br>

        [시그모이드 함수(sigmoid function)]
        h(x) = 1 / (1 + exp(-x))

        * exp(-x) = e^(-x)
        * e = 자연상수 (2.7182 ...)
        * 자연상수의 의미 : 자연의 연속성장을 표현하기 위한 상수
        * 100%의 성장률을 가지고 1회 연속 성장할 때 얻게 되는 성장량
        * e^x에서 지수 x의 의미 : 성장횟수*성장률

        시그모이드함수 그래프

![ ](./image/02.PNG)

<br>

        [계단함수와 시그모이드함수의 비교]
        - 시그모이드 함수는 '매끄럽다'
        - 계단 함수는 임계점을 기점으로 0 또는 1로 출력이 고정
        - 시그모이드 함수는 0.23, 0.9 등 출력이 연속적
        - 두 함수 모두 0과 1사이의 출력을 가지는 공통점이 있음
        - 두 함수 모두 비선형 함수임

<br>

        [렐루(ReLU : Rectified Linear Unit)함수]
        - 입력이 0을 넘으면 입력을 그대로 출력
        - 0 이하면 0을 출력

        렐루함수 그래프

![ ](./image/03.PNG)

<br>

        [소프트맥스(softmax) 함수]
        - 소프트맥스 함수의 분자는 입력신호의 지수함수, 분모는 모든 입력 신호의 지수함수의 합, 즉 소프트맥스의 출력층은 모든 입력신호로부터 영향을 받음
        - 소프트맥스 함수는 지수함수를 다루기 때문에, 수치가 굉장히 커지므로 overflow 문제가 발생할 위험이 높음
        - 따라서 최적화 식이 등장 : 입력신호에서 입력값중 최대값을 모두 빼주면 가능.
        - 소프트맥스 함수의 출력은 0과 1.0 사이의 실수이고, 모든 출력의 합은 1 (가장 중요한 성질)
        - 소프트맥스 함수의 출력을 확률로 이해할 수 있음
        - 소프트맥스는 지수함수를 사용하고, 지수함수는 단조함수이므로, 분류에서는 출력층에서 소프트맥스 함수를 생략함

<br>

        [MNIST 데이터셋]
        - 손글씨 데이터셋 - mnist.py에서 pickle을 통해 객체화 다운로드 가능

<br>

        [배치처리]
        - 배치 크기만큼 묶어서 데이터를 묶어서 동시에 추론 (효율적)

<br><br><br>

> #### [C.f.01.] 자연로그(ln)의 의미 : 어떤 성장량을 알고 있을 때, 성장 횟수와 성장률을 곱한 값을 역으로 계산해낼 수 있는 수학적 기술 (참고 : https://angeloyeo.github.io/2019/09/04/natural_number_e.html)
>
> 👉 ln(e^x) = x = 성장횟수\*성장률

> #### [C.f.02.] 기계학습 문제는 분류(classification)와 회귀(Regression)으로 나뉨. 분류는 데이터가 어떤 클래스에 속하는지 결정하는 문제이고, 회귀는 입력 데이터에서 (연속적인) 수치를 예측하는 문제

> #### [C.f.03.] 분류 문제에서는 출력 층의 뉴런 수와 분류 클래스 수를 같도록 설정함
